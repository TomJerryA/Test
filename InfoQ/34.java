<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8" /></head><body><h3>Spark Officially Graduates From Apache Incubator</h3><p>Recently, Spark <a href="http://www.datanami.com/datanami/2014-02-18/spark_graduates_apache_incubator.html">graduated</a> from the Apache incubator. Spark claims up to 100x speed improvements over Apache Hadoop over in-memory datasets and gracefully falling back to 10x speed improvement for on-disk performance. Since it was open sourced in 2010, Spark has been one of the <a href="http://www.youtube.com/watch?v=KspReT2JjeE#t=254">most active</a> projects in the community.</p>
<p>Its fast growth can be attributed to a number of reasons.&nbsp;It can combine its own <a href="https://spark.incubator.apache.org/examples.html">DSL</a> with <a href="http://shark.cs.berkeley.edu/">SQL</a> for leveraging of the well known SQL language. Spark’s primary API is a <a href="http://www.scala-lang.org/">Scala</a> DSL, built around a distributed collection of items called a Resilient Distributed Dataset (<a href="http://dev.bizo.com/2013/01/what-makes-spark-exciting.html">RDD</a>). An RDD can support bulk and aggregate operations like filter, map and reduceByKey, leveraging distributed execution. Shark can provide the same speed native Scala API using Hive SQL. Reusing <a href="http://hive.apache.org/">Hive</a>’s frontend and backend means that it can be used alongside Hive, sharing data, queries and UDFs.</p>
<p>Machine Learning algorithms come out of the box with <a href="https://spark.incubator.apache.org/mllib/">MLlib</a> providing a range of algorithms in classification, regression, clustering and recommendation fields. MLlib is just a component of <a href="http://www.mlbase.org/">MLBase</a>. <a href="http://ampcamp.berkeley.edu/wp-content/uploads/2013/07/amp_camp_8_30_13-1.pdf">MLBase</a> is a distributed Machine Learning system aiming to make Machine Learning tasks more accessible to both end-users and ML researchers. It’s the first system freeing users from algorithm choices and automatically optimizing for distributing execution. <a href="http://www.cs.berkeley.edu/~ameet/mlbase.pdf">Algorithm choices</a> are made based on best ML practices and a cost-based model. Distributed execution is similar to Apache <a href="https://mahout.apache.org/">Mahout</a> and is optimized for the data-access patterns of Machine Learning.</p>
<p>Graph algorithms can be implemented using <a href="http://amplab.github.io/graphx/">GraphX</a> that combines data-parallel and graph-parallel system semantics. GraphX offers comparable or better <a href="https://amplab.cs.berkeley.edu/wp-content/uploads/2014/02/graphx.pdf">performance</a> than Apache <a href="https://giraph.apache.org/">Giraph</a>, the established Graph processing system used at Facebook.</p>
<p><a href="http://amplab-extras.github.io/SparkR-pkg/">SparkR</a> exposes the Spark API to <a href="http://www.r-project.org/">R</a>, allowing statisticians to submit jobs directly from an R function into an Apache Spark cluster. R is the <a href="http://www.r-bloggers.com/in-data-scientist-survey-r-is-the-most-used-tool-other-than-databases/">most popular</a> tool for data scientists, other than RDBMS. Its main problem is that it is single threaded and inherently not designed for large data sets. SparkR overcomes these problems but comes with the caveat that it <a href="https://amplab.cs.berkeley.edu/2014/01/26/large-scale-data-analysis-made-easier-with-sparkr/">only works well</a> for inherently parallelizable algorithms like gradient descent.</p>
<p>Spark can be <a href="http://www.infoq.com/news/2014/01/Spark-Storm-Real-Time-Analytics">deployed</a> on Apache <a href="http://hadoop.apache.org/docs/r2.0.2-alpha/hadoop-yarn/hadoop-yarn-site/YARN.html">YARN</a>, providing easy integration and co-existence with heterogeneous systems. It also comes as part of <a href="http://vision.cloudera.com/reintroducing-cloudera-enterprise-now-with-apache-spark/">Cloudera Enterprise</a> data hub edition, backed by <a href="http://www.cloudera.com">Cloudera</a> and <a href="http://databricks.com/">Databricks</a>, the company behind Spark’s commercialization. Finally, <a href="https://spark.incubator.apache.org/streaming/">Streaming</a> can help with quick prototyping and applying useful distributed systems semantics. Spark’s code is available on <a href="https://github.com/apache/incubator-spark">GitHub</a>.</p><br><br><br><br><br><br></body></html>