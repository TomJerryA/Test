<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8" /></head><body><h3>DataFu在Apache进入孵化状态</h3><p><a href="https://www.linkedin.com/">LinkedIn</a>的<a href="https://github.com/linkedin/datafu">DataFu</a>项目是一个用于Hadoop的类库集合，于1月第1周在<a href="http://www.apache.org/">Apache软件基金会（ASF）</a>正式进入<a href="http://datafu.incubator.apache.org/">孵化状态</a>。</p>
<p>该项目创建于2012年1月，早期的定位是作为Pig项目的用户定义函数集（UDF ）。相对于更加通用的UDF集如<a href="https://cwiki.apache.org/confluence/display/PIG/PiggyBank">Piggybank</a>，Datafu更侧重于数据挖掘和统计 类的函数，例如分位数计算和取样方法。2013年10月，一个名为DataFu <a href="http://datafu.incubator.apache.org/blog/2013/10/03/datafus-hourglass-incremental-data-processing-in-hadoop.html">Hourglass</a>的新库加入到此项目。Hourglass是用于MapReduce的类库，为作业提供了处理增量数据的能力。其处理方式一般是在HDFS中保存上一个作业的状态，并用它来处理新的输入。现在这两个项目都成为孵化器的一部分。</p>
<p>DataFu在Apache进入孵化状态，是其前进过程中的一大步。任何项目都要经过<a href="http://incubator.apache.org/incubation/Incubation_Policy.html">严格的审查</a>，完成投票程序才能进入孵化器。2012年初创建的DataFu，2014年初才成功进入孵化器。通常，一个Apache项目完成孵化需要一定的时间，一旦项目的相关服务（wiki、邮件列表、教程等等）建设完成，DataFu将结束孵化，成为ASF的顶级项目或者Hadoop的子项目。</p>
<p>随着最近进入Apache孵化器，DataFu有了很多近期的发展计划。其中最关键的功能之一是为<a href="http://hive.apache.org/">Hive</a>和<a href="https://crunch.apache.org/">Crunch</a>提供同一UDF，以使其得到更大范围的应用。其中包括将项目的构建系统移植到<a href="http://www.gradle.org/">Gradle</a>，这些工作DataFu社区<a href="https://issues.apache.org/jira/browse/DATAFU-27">目前正在做</a>。构建系统从<a href="http://ant.apache.org/">Ant</a>改为Gradle的好处是能够巩固社区，使其以更简单的 流程添加新功能。</p>
<p>DataFu社区还比较小，但保持着稳定的增长。Russell Jurney最近的贡献使<a href="http://opennlp.apache.org/">Open NLP</a>项目成了DataFu 1.3.0的一部分。邮件列表中讨论的焦点是增加更多UDF，就像项目贡献者Matthew Hayes和Sam Shah所描述的，让DataFu成为“大数据的WD-40”。</p>
<p><strong>查看英文原文：</strong><a href="http://www.infoq.com/news/2014/02/datafu-asf">DataFu Enters Incubation Status at Apache</a></p>
<hr />
<p>感谢<a href="http://www.infoq.com/cn/author/臧秀涛">臧秀涛</a>对本文的审校。</p>
<p>给InfoQ中文站投稿或者参与内容翻译工作，请邮件至<a href="mailto:editors@cn.infoq.com">editors@cn.infoq.com</a>。也欢迎大家通过新浪微博（<a href="http://www.weibo.com/infoqchina">@InfoQ</a>）或者腾讯微博（<a href="http://t.qq.com/infoqchina">@InfoQ</a>）关注我们，并与我们的编辑和其他读者朋友交流。</p><br><br><br><br><br><br></body></html>