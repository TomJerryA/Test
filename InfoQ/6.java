<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8" /></head><body><h3>Spark Gets a Dedicated Big Data Platform</h3><p><a href="http://spark.apache.org/">Spark</a> users can now use a new Big Data platform provided by intelligence company <a href="http://atigeo.com/">Atigeo</a>, which bundles most of the <a href="https://amplab.cs.berkeley.edu/projects/">UC Berkeley stack</a> into a unified framework optimized for low-latency data processing that can provide significant improvements over more traditional <a href="http://hadoop.apache.org/">Hadoop</a>-based platforms.</p>
<p>The UC Berkeley offers as part of its stack a number of different projects to manage data processing at scale. While Hadoop has historically been the leader in Big Data systems, Spark has started gaining a lot of traction in the recent months, which culminated in March when Atigeo <a href="http://atigeo.com/news/atigeos-xpatterns-is-the-first-enterprise-grade-big-data-platform-leveraging-spark-shark-tachyon-and-mesos/">announced</a> the release of their xPatterns Big Data platform focused on Spark and other related projects. According to <a href="http://atigeo.com/about/biographies/david-talby/">David Talby</a>, SVP of Engineering at Atigeo, Spark has surpassed MapReduce as an execution framework and it is only natural to have a platform dedicated to it:</p>
<blockquote>
 We use HFDS as the underlying cheap storage, and will continue to do so, and some of our legacy customers still use MapReduce and Hive – both of which are still available within xPatterns. However, for new customers &amp; deployments we consider MapReduce a legacy technology and recommend all new code to be written in Spark as the lowest-level execution framework, given the substantial speed advantages and simpler programming model.
</blockquote>
<p>A common use cases when dealing with data at scale is to be able to query this data using SQL-like languages. Hadoop has <a href="https://hive.apache.org/">Hive</a>, Spark has <a href="http://spark.apache.org/">Shark</a>, and they both serve a similar purpose, but the performance considerations can vary. Hive has been historically slow, but has been going through a series of <a href="http://hortonworks.com/labs/stinger/">heavy improvements</a> which can improve its speed up to <a href="http://hortonworks.com/blog/45x-performance-increase-for-hive/">45 times</a>. When taking this into account, as well as the very active community behind Hive, it is easy to understand Atigeo's decision to support both Hive and Shark as explained by David:</p>
<blockquote>
 For SQL-like querying, we still support Hive side-by-side with Shark, since Shark does not yet fully support all the operators and edge cases that we require.
</blockquote>
<p>Spark is only one of the layers of the UC Berkeley stack, and there are other projects that can be used in enterprise-grade Big Data projects:</p>
<ul> 
 <li>Shark</li> 
 <li><a href="https://github.com/amplab/tachyon">Tachyon</a></li> 
 <li><a href="http://blinkdb.org/">BlinkDB</a></li> 
 <li><a href="http://www.mlbase.org/">MLbase</a></li> 
 <li><a href="https://github.com/amplab/graphx">GraphX</a></li> 
 <li>Spark streaming</li> 
</ul>
<p>Atigeo's platform includes Spark, Shark, but also Tachyon to provide easy and fast data sharing of data between Hadoop and Spark. For the remaining projects, Atigeo doesn't have anything to announce at the moment, but David mentions that Atigeo is &quot;evaluating these technologies and determining our plans to incorporate them in the future, as they mature and as our customers present concrete use cases that require them.&quot;</p>
<p>Also included in xPatterns is <a href="http://mesos.apache.org/">Apache Mesos</a>, &nbsp;a tool used to manage and share cluster resources among various data processing frameworks such as Hadoop or Spark. This enables users to efficiently allocate resources regardless of the framework being used. Mesos is very similar in nature to <a href="http://hadoop.apache.org/docs/r2.3.0/hadoop-yarn/hadoop-yarn-site/YARN.html">YARN</a> which is more often associated with the Hadoop stack, while Mesos was developed at UC Berkeley and so finds a more natural fit for Spark projects. David commented on why Atigeo decided to favor Mesos over YARN in their platform:</p>
<blockquote>
 Mesos was available earlier and more mature, and to date is more technically capable. Today, Spark on YARN only runs in static mode (coarse grained) – you allocate a fixed number of cores in memory from the cluster for each execution framework, which can only be used by that framework. In order to have better utilization, we use Spark on Mesos in dynamic mode (fine-grained), where the number of cores is allocated dynamically by Mesos. So for example, today we have MapReduce, Spark, and two Shark Servers running on Mesos – and any of these frameworks can get the cluster’s full resource capacity if the other frameworks are idle or under-utilized. Additionally, Mesos already supports other execution frameworks – Storm, Aurora, Chronos and Marathon are concrete examples that are of interest to us. As YARN matures or adds these capabilities and is able to support our customers’ needs, we expect to add support for it too.
</blockquote>
<p>The Spark community is going strong today, and even <a href="http://bigdataanalyticsnews.com/apache-spark-3-real-world-use-cases/">surpassing Hadoop MapReduce</a> in terms of number of contributors, so having a new Big Data platform giving more traction to Spark is good news, as <a href="http://gigaom.com/2014/03/27/apache-mahout-hadoops-original-machine-learning-project-is-moving-on-from-mapreduce/">other projects</a> are slowly shifting towards the Spark model.</p><br><br><br><br><br><br></body></html>