<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8" /></head><body><h3>Spark, Storm And Real Time Analytics</h3><p>Big Data Analytics have been advancing in the past years as the amount of information has exploded. Hadoop is definitely the platform of choice for Big Data analysis and computation. While data Volume, Variety and Velocity increases, Hadoop as a batch processing framework cannot cope with the requirement for real time analytics.</p>
<p>Databricks, the company behind <a href="http://spark.incubator.apache.org/">Apache Spark</a> recently raised $14 million from <a href="http://gigaom.com/2013/09/25/databricks-raises-14m-from-andreessen-horowitz-wants-to-take-on-mapreduce-with-spark/">Andreessen Horowitz</a> to accelerate development of Spark and <a href="https://github.com/amplab/shark/wiki">Shark</a>. Spark is an engine for large-scale data processing written in <a href="http://en.wikipedia.org/wiki/Scala_%28programming_language%29">Scala</a>, while Shark is a Hive compatible variation of Spark.</p>
<p>Like Spark, <a href="http://storm-project.net/">Storm</a> also aims to come around Hadoop’s batch nature by providing event processing and distributed computation capabilities. By designing a topology of transformations in a Directed Acyclic Graph, the architect can perform arbitrarily complex computations, one transformation at a time.</p>
<p><a href="https://twitter.com/nathanmarz">Nathan Marz</a> experienced it first hand and came up with the <a href="http://lambda-architecture.net/">lambda architecture</a> paradigm to solve this fundamental architectural problem. <a href="http://www.slideshare.net/nathan_gs/a-realtime-architecture-using-hadoop-and-storm-at-devoxx/24">Lambda architecture</a> consists of a serving layer that gets updated infrequently from the batch layer and a speed layer that computes real time analytics to compensate for the slow batch layer. Essentially, Hadoop is computing analytics in batches and in between batch runs, the speed layer is incrementally updating metrics by examining events in a streaming fashion.</p>
<p>Both Spark and Storm can operate in a Hadoop cluster and access Hadoop storage. <a href="http://developer.yahoo.com/blogs/ydn/storm-yarn-released-open-source-143745133.html">Storm-YARN</a> is Yahoo’s open source implementation of Storm and Hadoop convergence. Spark is providing <a href="http://spark.incubator.apache.org/docs/0.8.1/running-on-yarn.html">native integration</a> for Hadoop. Integration with Hadoop is achieved through <a href="http://hadoop.apache.org/docs/r2.0.2-alpha/hadoop-yarn/hadoop-yarn-site/YARN.html">YARN (NextGen MapReduce)</a>. Integrating real time analytics with Hadoop based systems allows for better utilization of cluster resources through computational elasticity and being in the same cluster means that network transfers can be minimal.</p>
<p>In terms of commercial support, Cloudera has already announced support for Spark and <a href="http://blog.cloudera.com/blog/2013/11/putting-spark-to-use-fast-in-memory-computing-for-your-big-data-applications/">included</a> it in <a href="http://www.cloudera.com/content/cloudera/en/products-and-services/cdh.html">CDH</a> (Cloudera’s Distribution Including Apache Hadoop). Hortonworks is <a href="http://hortonworks.com/blog/stream-processing-in-hadoop-yarn-storm-and-the-hortonworks-data-platform/">planning</a> to include Apache Storm in <a href="http://hortonworks.com/products/hdp/">HDP</a> (Hortonworks Data Platform) in the first half of 2014.</p><br><br><br><br><br><br></body></html>