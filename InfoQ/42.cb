<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8" /></head><body><h3>Hadoop na nuvem</h3><p>Os provedores de solu&ccedil;&otilde;es <a href="http://www.google.com/url?q=http%3A%2F%2Fhadoop.apache.org%2F%23What%2BIs%2BApache%2BHadoop%253F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHwatn_kppnS_S5tyRqYItIoBgrZA">Hadoop</a>, atualmente dentre as mais populares tecnologias de Big Data nos ambientes de nuvem p&uacute;blica ou privada evolu&iacute;ram por&eacute;m, algumas quest&otilde;es devem ser analisadas. O Hadoop &eacute; adequado para ser utilizado nestes ambientes? Estes pacotes de servi&ccedil;o s&atilde;o confi&aacute;veis? Estes servi&ccedil;os s&atilde;o &uacute;teis? Quais s&atilde;o os fornecedores? Este artigo apresenta uma vis&atilde;o geral sobre a utiliza&ccedil;&atilde;o do Hadoop na Nuvem.</p>
<p><em>(Nota: por nuvem privada, neste artigo, leia-se nuvem privada virtual, fora do ambiente da empresa)</em></p>
<h1>Mas o Hadoop n&atilde;o foi projetado para rodar em m&aacute;quinas f&iacute;sicas?</h1>
<p>Sim. Especificamente, seus 2 principais componentes, o HDFS para armazenamento dos dados, e o Map-Reduce, respons&aacute;vel pelo processamento foram projetados para serem utilizados em ambientes f&iacute;sicos espec&iacute;ficos pelas seguintes raz&otilde;es:</p>
<ol class="c13 lst-kix_vyl53abd9cb6-0 start" start="1"> 
 <li>Surgimento de novas restri&ccedil;&otilde;es t&eacute;cnicas - Hoje o problema j&aacute; n&atilde;o &eacute; a pot&ecirc;ncia da CPU ou a capacidade do disco. H&aacute; <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.ll.mit.edu%2FHPEC%2Fagendas%2Fproc04%2Finvited%2Fpatterson_keynote.pdf&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNETZTzj5senb8-TQ1xa38YKnf5uZQ">um par&acirc;metro que n&atilde;o cresce t&atilde;o r&aacute;pido</a> quanto os outros regidos pela Lei de Moore: &eacute; a lat&ecirc;ncias de I/O, do disco e da rede. Por 100 reais a cada 18 meses, tem-se o dobro do espa&ccedil;o em disco, por&eacute;m o crescimento do disco leva &agrave; necessidade de mais tempo para acessar este volume de dados.</li> 
 <li>Paraleliza&ccedil;&atilde;o do acesso - Tenta-se sempre paralelizar o canal CPU/disco. Por esse motivo que recomenda-se a configura&ccedil;&atilde;o do Hadoop com unidades internas em <a href="http://www.google.com/url?q=http%3A%2F%2Fsearchstorage.techtarget.com%2Fdefinition%2FJBOD&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEE4QOKmw0dsu4tc7l7oIFWZJRgNg">JBOD</a> e um disco para cada n&uacute;cleo do processador (ou um pouco mais). E, al&eacute;m disso, distribui-se o processamento em muitas m&aacute;quinas para paralelizar a rede.</li> 
 <li>Mudan&ccedil;a na l&oacute;gica dos custos de configura&ccedil;&otilde;es de hardware - Em datacenters utilizados pelos <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.octo.com%2Ffr%2Fpublications%2F11-les-geants-du-web&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFGnsbqT11feiOFdpvbOiSIdgRFIA">Gigantes da Web</a>, o uso de v&aacute;rias <a href="http://www.google.com/url?q=http%3A%2F%2Fbnrg.eecs.berkeley.edu%2F~randy%2FCourses%2FCS294.F09%2Fwharehousesizedcomputers.pdf&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHaiRnwVd7tEYBrXxbs7GHz-M5GQA">m&aacute;quinas de baixo custo &eacute; mais eficiente</a> do que m&aacute;quinas high-end com v&aacute;rias redund&acirc;ncias de hardware, mesmo considerando uma replica&ccedil;&atilde;o de dados tripla. &Eacute; por isso que HDFS, e antes dele o Google GFS, <a href="http://www.google.com/url?q=http%3A%2F%2Fwiki.apache.org%2Fhadoop%2FVirtual%2520Hadoop&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGYvuMVJgmRYnZjVyiENQbAcxVQtQ">foi projetado para rodar em clusters com um grande n&uacute;mero de n&oacute;s n&atilde;o confi&aacute;veis</a>, replicando os dados de forma inteligente em diferentes m&aacute;quinas, e em diferentes racks, de modo que uma falha em um determinado hardware n&atilde;o impacte sobre as demais c&oacute;pias.</li> 
</ol>
<p>Estes dois elementos de design, discos internos e estrat&eacute;gia de replica&ccedil;&atilde;o de dados baseadas em topologia f&iacute;sica, s&atilde;o dif&iacute;ceis ou imposs&iacute;veis de se reproduzir em um ambiente virtualizado com <a href="http://www.google.com/url?q=http%3A%2F%2Fpt.wikipedia.org%2Fwiki%2FRede_de_%25C3%25A1rea_de_armazenamento&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNE1Lb7rbwZifVHFRigYcEZ5EIh_lA">infraestrutura SAN</a>. Em um ambiente de nuvem, &eacute; ainda pior, pois se tem pouca ou nenhuma informa&ccedil;&atilde;o sobre a topologia da infraestrutura.</p>
<p>Existem casos em que um ambiente virtual seria vi&aacute;vel? Sim. Levando-se em conta estas limita&ccedil;&otilde;es, ou seja, dando a aten&ccedil;&atilde;o devida sobre o I/O e as estrat&eacute;gias de replica&ccedil;&atilde;o de dados, o <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.vmware.com%2Ffiles%2Fpdf%2FBenefits-of-Virtualizing-Hadoop.pdf&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFq2bMp1UveAlmb1k3CQrmNHdVc-Q">Hadoop funciona bem em infraestrutura SAN compartilhada e em clusters de pequena ou m&eacute;dia dimens&otilde;es</a>.</p>
<h1>O que podemos esperar em termos de performance?</h1>
<p>A VMWare fez um estudo do <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.vmware.com%2Ffiles%2Fpdf%2Ftechpaper%2FVMW-Hadoop-Performance-vSphere5.pdf&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNG5mqQm5xup4LwI4R7GE2ePdBCbSg">impacto da virtualiza&ccedil;&atilde;o na performance dos processamentos</a>. Em um benchmark, foram analisadas caracter&iacute;sticas b&aacute;sicas: <em>CPU-bound</em>, <em>disk-bound</em>, ou o uso intensivo de rede. Os resultados s&atilde;o encorajadores e at&eacute; mesmo surpreendentes, j&aacute; que variam de uma diminui&ccedil;&atilde;o de 4% em alguns processamentos, a uma melhora de at&eacute; 14% de outros. Segundo o estudo da VMWare, esta melhoria deve-se &agrave; otimiza&ccedil;&atilde;o do uso de CPU pelo <a href="http://www.google.com/url?q=http%3A%2F%2Fpt.wikipedia.org%2Fwiki%2FHipervisor&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFNe4rPZqKYxPP_21uipcxVedvmzg">hipervisor</a>, e a uma melhor estrat&eacute;gia em algumas situa&ccedil;&otilde;es espec&iacute;ficas.</p>
<div id="lowerFullwidthVCR"></div>
<p>Deve-se notar que certas fun&ccedil;&otilde;es de gerenciamento de desempenho do cluster (<a href="https://www.google.com/url?q=https%3A%2F%2Fwww.inkling.com%2Fread%2Fhadoop-definitive-guide-tom-white-3rd%2Fchapter-6%2Ftask-execution&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGZp4r2dp03PJASzuYiokQGmq77Gw">speculative execution</a>) foram desativadas, por serem claramente incompat&iacute;veis com o trabalho do hypervisor.</p>
<p>De qualquer maneira estes trabalhos b&aacute;sicos n&atilde;o representam necessariamente os processamentos encontrados no dia-a-dia. Uma vez na nuvem, deve-se considerar sempre uma performance um pouco menor (que voc&ecirc; pode compensar atrav&eacute;s da aloca&ccedil;&atilde;o de mais m&aacute;quinas), ou vari&aacute;vel entre uma e outra execu&ccedil;&atilde;o.</p>
<h1>A rela&ccedil;&atilde;o pre&ccedil;o / desempenho &eacute; boa?</h1>
<p>A Accenture fez recentemente um <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.accenture.com%2FSiteCollectionDocuments%2FPDF%2FAccenture-Hadoop-Deployment-Comparison-Study.pdf&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFJT7-lkcOHAS7GL2KNH24V9Ividg">estudo</a> que compara o TCO (<a href="http://www.google.com/url?q=http%3A%2F%2Fpt.wikipedia.org%2Fwiki%2FTotal_cost_of_ownership&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEHkLeVM5OTGJaTyUtdVL4jfeNz7Q">Total Cost of Ownership</a>) de m&aacute;quinas f&iacute;sicas e de uma configura&ccedil;&atilde;o na nuvem (<a href="http://www.google.com/url?q=http%3A%2F%2Faws.amazon.com%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFnRZErlBb0t_Um8-YTxLlJ0AMbkQ">AWS</a>). Esta compara&ccedil;&atilde;o foi realizada com processamentos complexos e representativos de um projeto de big-data.</p>
<p>A conclus&atilde;o do estudo da Accenture &eacute; que a rela&ccedil;&atilde;o pre&ccedil;o / desempenho &eacute; melhor na AWS. Este estudo &eacute; question&aacute;vel em alguns pontos - como a depend&ecirc;ncia entre o resultado e v&aacute;rias hip&oacute;teses num&eacute;ricas estabelecidas pelos autores; e a configura&ccedil;&atilde;o subdimensionada do hardware escolhido - apesar disso, pode-se concluir que as duas configura&ccedil;&otilde;es tem a rela&ccedil;&atilde;o pre&ccedil;o / desempenho na mesma ordem de grandeza.</p>
<p>A segunda conclus&atilde;o deste estudo &eacute; que o trabalho de otimiza&ccedil;&atilde;o do processamento &eacute; essencial, e no caso deles, trouxe um ganho na ordem de 8 vezes. Vale mais a pena usar a sua energia para melhorar a estrutura e a performance do processamento, do que gastar tempo buscando um desconto de 20% no pre&ccedil;o do fornecedor.</p>
<p>Al&eacute;m do custo do cluster, outros custos relacionados com a nuvem devem ser considerados, em particular, os custos relacionados &agrave; transfer&ecirc;ncia de dados para dentro e para fora da nuvem. <a href="http://www.google.com/url?q=http%3A%2F%2Fwiki.apache.org%2Fhadoop%2FVirtual%2520Hadoop&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGYvuMVJgmRYnZjVyiENQbAcxVQtQ">A Apache recomenda</a> cautela quanto &agrave; confiabilidade do armazenamento HDFS virtualizado na nuvem, e recomenda considerar o uso de um armazenamento auxiliar tipo AWS S3, Azure Blob, etc.</p>
<h1>Quais s&atilde;o as op&ccedil;&otilde;es de pacotes de servi&ccedil;o na nuvem?</h1>
<p>Existem v&aacute;rias ofertas de pacotes de servi&ccedil;o com caracter&iacute;sticas bastante distintas, dentre as quais destacam-se:</p>
<p><em>Nota</em><em>: est&atilde;o aqui listados os provedores que oferecem produtos em nuvem p&uacute;blica, suficientemente claros e documentados, para serem utilizados assim que conclu&iacute;da a leitura deste artigo. N&atilde;o foram avaliados fornecedores que oferecem somente nuvem privada (o que exigiria trabalhar junto as suas equipes), e fornecedores que est&atilde;o mais para marketing de big-data do que para ofertas plug'n'play.</em></p>
<h2>IaaS</h2>
<p>Nesta categoria, voc&ecirc; tem produtos <a href="http://www.google.com/url?q=http%3A%2F%2Fen.wikipedia.org%2Fwiki%2FIAAS&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNESVjWka585RrM7IzEw5VXonPaJZg">IaaS</a> de prateleira, distribui&ccedil;&otilde;es de Hadoop pr&eacute;-montadas e prontas, na forma de imagens para utilizar nas suas VMs.</p>
<p>Voc&ecirc; escolhe o tamanho da m&aacute;quina que precisa, e instala a imagem fornecida. O resultado &eacute; um cluster de processamento + armazenamento, t&iacute;pico de Hadoop.</p>
<ul class="c13 lst-kix_ycww4ta8r2gi-0 start"> 
 <li>Se &eacute; uma oferta de prateleira, ent&atilde;o presume-se que voc&ecirc; v&aacute; economizar tempo na configura&ccedil;&atilde;o do cluster, e evitar algumas armadilhas de desempenho (isso merece um &quot;benchmark&quot;, e poder&aacute; ser objeto de um artigo futuro).</li> 
 <li>Pode-se come&ccedil;ar com as imagens de VM fornecidas, e personaliz&aacute;-las adicionando uma ou outra lib.</li> 
 <li>Uma desvantagem &eacute; que, comparando com pr&oacute;xima categoria, esta n&atilde;o &eacute; muito plug'n'play. Voc&ecirc; tem que gerenciar por si mesmo name-nodes, task-trackers, etc.</li> 
 <li>Outra restri&ccedil;&atilde;o &eacute; que voc&ecirc; n&atilde;o pode desligar o cluster para reduzir custos, j&aacute; que os n&oacute;s t&ecirc;m fun&ccedil;&atilde;o dupla: processamento e armazenamento. Para reduzir os custos, &eacute; necess&aacute;rio remover m&aacute;quinas, o que implica em mover antes os dados para outro armazenamento.</li> 
</ul>
<p>Poss&iacute;veis fornecedores:</p>
<ul class="c13 lst-kix_olaa1ddkzwmu-0 start"> 
 <li><a href="http://www.google.com/url?q=http%3A%2F%2Fwww.rackspace.com%2Fknowledge_center%2Farticle%2Fgetting-started-with-apache-hadoop-on-rackspace-cloud&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHir-tjVWn82KY7BZ4QOhk3girgeQ">Rackspace + Hortonworks</a></li> 
 <li><a href="http://www.google.com/url?q=http%3A%2F%2Fwiki.joyent.com%2Fwiki%2Fdisplay%2Fjpc2%2FJoyent%2BHadoop%2BSmartMachine&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEnUiW1GUWaDF5ASLb1gOBzxk2Vvg">Joyent + Hortonworks</a></li> 
 <li><a href="http://www.google.com/url?q=http%3A%2F%2Fwww.gogrid.com%2Fsolutions%2Fhadoop&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGtfN_e2eCUAXoSPpLopMbfoIQN2A">GoGrid + Cloudera CDH</a></li> 
</ul>
<p>Observe que as m&aacute;quinas do Rackspace parecem um pouco pequenas para o contexto Hadoop, tornando a oferta pouco competitiva.</p>
<p>Alternativamente voc&ecirc; pode escolher o provedor de IaaS e a distribui&ccedil;&atilde;o Hadoop separadamente, o que eu recomendo apenas nos seguintes casos:</p>
<ul class="c13 lst-kix_um7rvnt324m1-0 start"> 
 <li>voc&ecirc; quer usar um provedor de IaaS espec&iacute;fico (porque voc&ecirc; j&aacute; tem uma nuvem privada, ou voc&ecirc; tem restri&ccedil;&otilde;es regulamentares, como, por exemplo, a localiza&ccedil;&atilde;o dos dados)</li> 
 <li>voc&ecirc; quer usar uma distribui&ccedil;&atilde;o muito recente do Hadoop, ainda em vers&atilde;o beta, ou mesmo personalizada por voc&ecirc;.</li> 
</ul>
<p>Voc&ecirc; corre o risco de ter que gastar muito tempo ajustando a distribui&ccedil;&atilde;o e as configura&ccedil;&otilde;es do cluster para essa nuvem, e para obter um bom desempenho.</p>
<h2>&quot;Hadoop-as-a-Service&quot;</h2>
<p>Nesta categoria temos solu&ccedil;&otilde;es muito mais empacotadas e automatizadas. N&atilde;o h&aacute; necessidade de se gerenciar <a href="http://www.google.com/url?q=http%3A%2F%2Fbradhedlund.com%2F2011%2F09%2F10%2Funderstanding-hadoop-clusters-and-the-network%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFvuh6iJDWjlCaWqMjtW-kK0VU16Q">name-nodes, task-trackers &amp; cia</a>. Boa parte do trabalho j&aacute; est&aacute; feito, de forma bem transparente.</p>
<p>Op&ccedil;&atilde;o 1: Voc&ecirc; quer um cluster Hadoop &quot;cl&aacute;ssico&quot; processamento + armazenamento.</p>
<p>Pacotes:</p>
<ul class="c13 lst-kix_otzrkzq2flvh-0 start"> 
 <li>Azure HDInsight , com base na distribui&ccedil;&atilde;o Hortonworks (descri&ccedil;&atilde;o <a href="http://www.google.com/url?q=http%3A%2F%2Fblog.octo.com%2Fhdinsight-le-big-data-selon-microsoft%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNETE7BAO__t2kXvprP7YoIQkYRfDw">neste artigo</a> - em franc&ecirc;s)</li> 
 <li>AWS Elastic -Map- Reduce, usando a distribui&ccedil;&atilde;o MapR (<a href="http://www.google.com/url?q=http%3A%2F%2Faws.amazon.com%2Fpt%2Felasticmapreduce%2Fmapr%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEV9vVQTOwGxHOrhSzMRQDZqmom0w">vers&atilde;o M3 , M5 , M7</a> ou &agrave; sua escolha)</li> 
 <li><a href="http://www.google.com/url?q=http%3A%2F%2Fwww.datazoomr.com%2Findex.php%2Fdatazoomr-public-plateforme-big-data-opensource-hadoop-as-a-service&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHyqL8qpaCzHaxn2tG-WXh-MoFVLA">VirtualScale Datazoomr</a> na Cloudera, oferta recente, em crescimento na Fran&ccedil;a.</li> 
</ul>
<p>Neste caso, voc&ecirc; ter&aacute; um cluster completo, com alguma flexibilidade, especialmente para o uso de dados de outro armazenamento (AWS S3, Azure Blob Storage), ou ainda para instanciar n&oacute;s de computa&ccedil;&atilde;o (workers sem armazenamento).</p>
<p>Op&ccedil;&atilde;o 2: Indo mais longe nesta abordagem PaaS, deveria ser poss&iacute;vel utilizar apenas componentes espec&iacute;ficos do universo Hadoop, que seriam cobrados pela utiliza&ccedil;&atilde;o.</p>
<p>Por exemplo, use apenas o Map-Reduce num cluster transit&oacute;rio. De zero a dezenas de n&oacute;s em quest&atilde;o de minutos, sem armazenamento persistente no HDFS. Com a oferta AWS Elastic Map-Reduce e sua pr&oacute;prio distribui&ccedil;&atilde;o Hadoop (&quot;standard Amazon&quot;), ou com a distribui&ccedil;&atilde;o do desafiante <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.joyent.com%2Fproducts%2Fmanta&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNG72JTD9ag2ssvLmcrZzPkYIF8ilw">Joyent Manta</a>, o uso t&iacute;pico &eacute; armazenar dados em um object-store (S3 ou Manta) e depois instanciar os n&oacute;s de processamento Map-Reduce para um bloco de trabalho. Os dados s&atilde;o lidos diretamente do object-store, ou podem ser copiados para armazenamento local (HDFS) . No final do processamento, o resultado &eacute; retornado no object-store e os n&oacute;s s&atilde;o removidos. Aqui voc&ecirc; vai pagar de um lado o armazenamento (volume e transfer&ecirc;ncias), e do outro lado o processamento, em tempo consumido de CPU.</p>
<p>Outro exemplo: usar somente o recurso de consulta SQL para volumes gigantes. A Google oferece o seu famoso <a href="http://research.google.com/pubs/pub36632.html">Dremel</a> - que a comunidade Hadoop est&aacute; tentando recriar - no pacote Google BigQuery. <a href="http://www.google.com/url?q=http%3A%2F%2Ftechcrunch.com%2F2013%2F09%2F18%2Fgoogles-bigquery-introduces-streaming-inserts-and-time-based-queries-for-real-time-analytics%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHdmAtAbd2oQHI-6aXkU-w0xvogZw">Voc&ecirc; pode injetar os dados em fluxo, e fazer uma an&aacute;lise interativa</a>. Voc&ecirc; paga para o armazenamento, e o volume manipulado nas suas an&aacute;lises.</p>
<p>Um &uacute;ltimo exemplo, ir para um armazenamento NoSQL e manipular os dados em opera&ccedil;&otilde;es de Map-Reduce. Ofertas como AWS e MapR, ou ainda <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.infochimps.com%2Finfochimps-cloud%2Foverview%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNERK39r5Dkbc8uz3ty-neDJGZDPpg">InfoChimps</a>, permitem construir esse tipo de arquitetura.</p>
<p>Nesta categoria &quot;Hadoop as a Service&quot;, h&aacute; uma grande flexibilidade, e, dependendo de suas necessidades, muitos pacotes diferentes. Os pre&ccedil;os s&atilde;o muito dif&iacute;ceis de comparar (para se convencer disto basta olhar para as tabelas de pre&ccedil;os da AWS). O mercado est&aacute; &agrave; pleno vapor!</p>
<h2>&quot;Analytics-as-a-Service&quot;</h2>
<p>Para completar este panorama de servi&ccedil;os na nuvem, devemos mencionar os pacotes de prateleira de servi&ccedil;os de an&aacute;lise. Voc&ecirc; fornece os dados, e pode consumir os resultados dos algoritmos de an&aacute;lise, ou de <a href="http://www.google.com/url?q=http%3A%2F%2Fen.wikipedia.org%2Fwiki%2FMachine_learning&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGsa2xd5cYdu0bAjxt5KVpNaDQQow">machine learning.</a></p>
<p>Como exemplos temos o <a href="http://www.google.com/url?q=http%3A%2F%2Fsoftware.intel.com%2Fcloudservicesplatform%2Fservice%2Frecommendation-catalog-and-curation-services&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGm6jGBtjtaakkFpc0_yB-kb1ryjw">Intel Cloud Services</a> que fornece um mecanismo de recomenda&ccedil;&atilde;o de itens personalizados, alimentado pelos dados que voc&ecirc; fornece, ou seja, pelos dados de avalia&ccedil;&atilde;o desses itens pelos usu&aacute;rios (compras ou opini&otilde;es); ou ainda o <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.kxen.com%2FCloud&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNF_P0LSrugkADmdjr2e0qRqg-Ch4A">KXEN</a>, que oferece servi&ccedil;os de apoio &agrave; venda integrados aos servi&ccedil;os dos aplicativos Salesforce.</p>
<p>No entanto, isso est&aacute; al&eacute;m do escopo deste artigo, j&aacute; que nestes casos a tecnologia Hadoop n&atilde;o &eacute; vis&iacute;vel. Ela est&aacute; escondida atr&aacute;s das APIs, e totalmente gerenciada pelo provedor. Mais uma vez, o mercado ainda &eacute; muito jovem, mas j&aacute; oferece pacotes ricos e variados.</p>
<h1>Conclus&atilde;o</h1>
<p>Algumas empresas possuem restri&ccedil;&otilde;es de hospedagem (espa&ccedil;o dispon&iacute;vel, custos de provisionamento, capacidade t&eacute;cnica do time) que n&atilde;o lhes permitem configurar rapidamente uma grande quantidade de m&aacute;quinas necess&aacute;rias para o Hadoop (hardware commodity, JBOD) para construir um cluster de pequeno ou m&eacute;dio porte.</p>
<p>Em outros casos, temos projetos de inova&ccedil;&atilde;o para os quais n&atilde;o sabemos estimar com precis&atilde;o o tamanho do cluster que ser&aacute; necess&aacute;rio, ou mesmo qual ser&aacute; a sua taxa de utiliza&ccedil;&atilde;o.</p>
<p>Criar um cluster Hadoop na nuvem &eacute; uma op&ccedil;&atilde;o vi&aacute;vel, e as tecnologias oferecidas por esses provedores s&atilde;o confi&aacute;veis e est&atilde;o ganhando mais maturidade. Tome cuidado com a quest&atilde;o da durabilidade dos dados, caso os dados n&atilde;o estejam presentes na nuvem, e com a performance de I/O do armazenamento na nuvem.</p>
<p>O ganho imediato &eacute; definitivamente a agilidade para come&ccedil;ar seu projeto. Voc&ecirc; pode come&ccedil;ar amanh&atilde;! Haver&aacute; tempo para racionalizar e internalizar mais tarde, se isso fizer sentido, mas voc&ecirc; j&aacute; ter&aacute; uma id&eacute;ia melhor da sua real necessidade com o Hadoop.</p>
<h2><strong>Sobre o autor:</strong></h2>
<p>Mathieu &eacute; especialista em BigData na OCTO Technology. Ele &eacute; graduado (2001) em engenharia de software e computador pela ENSEIRB na Fran&ccedil;a. Teve responsabilidade em contextos muito variados, como arquiteto s&ecirc;nior e consultor.</p>
<p>Ele possui interesse em arquiteturas escal&aacute;veis​​ e de alto desempenho: Hadoop, NoSQL, sistemas transacionais distribu&iacute;das, processamento de fluxo de eventos, computa&ccedil;&atilde;o em nuvem e atua em atividades de Investiga&ccedil;&atilde;o e Desenvolvimento na OCTO.</p>
<p>Mathieu palestrou em v&aacute;rias confer&ecirc;ncias : TDC 2013 S&atilde;o Paulo, Agile France, Lean-Kanban France, Agile Tour Brussels.</p><br><br><br><br><br><br></body></html>