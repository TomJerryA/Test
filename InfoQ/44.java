<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8" /></head><body><h3>Running Spark on R with SparkR</h3><p>R is still one of the most powerful languages for data scientists, and the bar was raised even further at the end of January 2014 when UC Berkeleyâ€™s <a href="https://amplab.cs.berkeley.edu/">AMPLab</a> announced a <a href="https://groups.google.com/forum/#!topic/apache-spark-user-mirror/tZs0dHeM6bk">developer preview</a> of their new project SparkR to use Apache Spark natively from R.</p>
<p>A Big Data framework for in-memory data processing at scale, <a href="http://spark.incubator.apache.org/">Apache Spark</a> has been gaining a lot of traction lately as big companies likes Cloudera are throwing their weight behind the project. Cloudera recently announced that <a href="http://blog.cloudera.com/blog/2014/02/spark-is-now-generally-available-for-cloudera-enterprise/">Spark is now officially supported</a> in its Cloudera Distribution for Hadoop (CDH) from version 4.4.0 onwards. This includes the most recent release of <a href="http://spark.incubator.apache.org/news/spark-0-9-0-released.html">Spark 0.9</a> which was released in February, and is a pre-requisite for SparkR. SparkR comes at the right time as CDH is one of the most popular Hadoop distributions, so this will help drive adoption towards the data science crowd which may be more familiar with R than Java or Scala, as shown by a <a href="http://blog.revolutionanalytics.com/2014/01/in-data-scientist-survey-r-is-the-most-used-tool-other-than-databases.html">recent survey of data scientists</a> by O'Reilly.</p>
<p>SparkR should be seen as a lightweight frontend to use Spark from R, meaning it will not have an API as extensive as the Scala or Java bindings, but will be sufficient to run Spark jobs from R and manipulate data. One of its key features is the ability to serialize closures, which in turn transparently copies variables to a Spark cluster if they are needed in a computation. SparkR also integrates with other R modules via a built-in function that can tell the Spark cluster to load a particular module needed for a computation, but, unlike closures, this needs to be specified manually. More details around the technical capabilities of SparkR can be found <a href="http://amplab-extras.github.io/SparkR-pkg/">in this summary</a>. SparkR can also take advantage of Spark's <a href="http://spark.incubator.apache.org/docs/latest/ec2-scripts.html">EC2 scripts</a> to be easily setup on EC2, and <a href="https://github.com/amplab-extras/SparkR-pkg/wiki/SparkR-on-EC2">some instructions</a>&nbsp;around that can be found on Github.</p>
<p>The data science crowd has been pretty vocal about SparkR, and Twitter in particular had many support messages for the project. <a href="https://twitter.com/alexcpsec">Alex Pinto</a>, lead at <a href="http://www.mlsecproject.org/">MLSecProject</a>,&nbsp;for example tweeted the following:</p>
<blockquote> 
 <p>This is very promising: SparkR by @amplab. Puts together my favorite things for data analysis.</p> 
</blockquote>
<p>The project is <a href="http://github.com/amplab-extras/SparkR-pkg">on Github</a> and already has a pretty active community with close to 100 stars. Considering that the project is barely a month old, this is some significant growth. There are also several open issues, meaning the community is actively involved in this new open-source project.</p>
<p>The AMPLab team has expressed interest in the future to integrate SparkR with Spark's <a href="http://spark.incubator.apache.org/mllib/">MLlib</a> machine learning library so that algorithms can be parallelized seamlessly without having to specify manually which part of the algorithm can be run in parallel. MLlib is one of the components in a larger machine learning project called <a href="http://www.mlbase.org/">MLBase</a> which also includes higher-level abstractions and an optimizer. MLlib is one of the fastest growing machine learning libraries with more than 137 contributors, so adding the ability to use it from R makes a lot of sense for AMPLab to ensure contributions to MLlib from R users.</p><br><br><br><br><br><br></body></html>