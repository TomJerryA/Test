<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8" /></head><body><h3>Lambda表达式让Spark编程更容易</h3><p>近日，Databricks官方网站发表了一篇<a href="http://databricks.com/blog/2014/04/14/Spark-with-Java-8.html">博文</a>，用示例说明了lambda表达式如何让Spark编程更容易。文章开头即指出，Spark的主要目标之一是使编写大数据应用程序更容易。Spark的Scala和Python接口一直很简洁，但由于缺少函数表达式，Java API有些冗长。因此，随着Java 8增加了<a href="http://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html">lambda表达式</a>，他们更新了Spark的API。Spark 1.0将提供Java 8 lambda表达式支持，而且与Java的旧版本保持兼容。该版本将在5月初发布。</p>
<p>文中举了两个例子，用于说明Java 8如何使代码更简洁。第一个例子是使用Spark的filter和count算子在一个日志文件中查找包含“error”的行。这很容易实现，但在Java 7中需要向filter传递一个Function对象，这有些笨拙：</p>
<pre>
JavaRDD&lt;String&gt; lines = sc.textFile(&quot;hdfs://log.txt&quot;).filter(
new Function&lt;String, Boolean&gt;() {
public Boolean call(String s) {
return s.contains(&quot;error&quot;);
}
});
long numErrors = lines.count();
</pre>
<p>在Java 8中，代码更为简洁：</p>
<pre>
JavaRDD&lt;String&gt; lines = sc.textFile(&quot;hdfs://log.txt&quot;)
.filter(s -&gt; s.contains(&quot;error&quot;));
long numErrors = lines.count();
</pre>
<p>当代码更长时，对比更明显。文中给出了第二个例子，读取一个文件，得出其中的单词数。在Java 7中，实现代码如下：</p>
<pre>
JavaRDD&lt;String&gt; lines = sc.textFile(&quot;hdfs://log.txt&quot;);
//将每一行映射成多个单词
JavaRDD&lt;String&gt; words = lines.flatMap(
new FlatMapFunction&lt;String, String&gt;() {
public Iterable&lt;String&gt; call(String line) {
return Arrays.asList(line.split(&quot; &quot;));
}
});
// 将单词转换成(word, 1)对
JavaPairRDD&lt;String, Integer&gt; ones = words.mapToPair(
new PairFunction&lt;String, String, Integer&gt;() {
public Tuple2&lt;String, Integer&gt; call(String w) {
return new Tuple2&lt;String, Integer&gt;(w, 1);
}
});
// 分组并按键值添加对以产生计数
JavaPairRDD&lt;String, Integer&gt; counts = ones.reduceByKey(
new Function2&lt;Integer, Integer, Integer&gt;() {
public Integer call(Integer i1, Integer i2) {
return i1 + i2;
}
});
counts.saveAsTextFile(&quot;hdfs://counts.txt&quot;);
</pre>
<p>而在Java 8中，该程序只需要几行代码： JavaRDD&lt;String&gt; lines = sc.textFile(&quot;hdfs://log.txt&quot;); JavaRDD&lt;String&gt; words = lines.flatMap(line -&gt; Arrays.asList(line.split(&quot; &quot;))); JavaPairRDD&lt;String, Integer&gt; counts = words.mapToPair(w -&gt; new Tuple2&lt;String, Integer&gt;(w, 1)) .reduceByKey((x, y) -&gt; x + y); counts.saveAsTextFile(&quot;hdfs://counts.txt&quot;);</p>
<p>要了解更多关于Spark的信息，可以查看<a href="http://spark.apache.org/docs/latest/index.html">官方文档</a>。Spark只需<a href="http://spark.apache.org/downloads.html">下载</a>解压即可运行，而无须安装。</p>
<hr />
<p>感谢<a href="http://www.infoq.com/cn/author/辛湜">辛湜</a>对本文的审校。</p>
<p>给InfoQ中文站投稿或者参与内容翻译工作，请邮件至<a href="mailto:editors@cn.infoq.com">editors@cn.infoq.com</a>。也欢迎大家通过新浪微博（<a href="http://www.weibo.com/infoqchina">@InfoQ</a>）或者腾讯微博（<a href="http://t.qq.com/infoqchina">@InfoQ</a>）关注我们，并与我们的编辑和其他读者朋友交流。</p><br><br><br><br><br><br></body></html>