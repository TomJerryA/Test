<html><head><meta http-equiv="content-type" content="text/html; charset=utf-8" /></head><body><h3>SparkR发布 让R跑在Spark上</h3><p><a href="http://amplab-extras.github.io/SparkR-pkg/">SparkR</a>是AMPLab发布的一个R开发包，为Apache Spark提供了轻量的前端。SparkR提供了Spark中弹性分布式数据集（RDD）的API，用户可以在集群上通过R shell交互性的运行job。例如，我们可以在HDFS上读取或写入文件，也可以使用 lapply 来定义对应每一个RDD元素的运算。</p>
<pre>
sc &lt;- sparkR.init(&quot;local&quot;)
  lines &lt;- textFile(sc, &quot;hdfs://data.txt&quot;)
  wordsPerLine &lt;- lapply(lines, function(line) { length(unlist(strsplit(line, &quot; &quot;))) })
</pre>
<p>除了常见的RDD函数式算子reduce、reduceByKey、groupByKey和collect之外，SparkR也支持利用 lapplyWithPartition 对每个RDD的分区进行操作。</p>
<p>SparkR也支持常见的闭包（closure）功能：用户定义的函数中所引用到的变量会自动被发送到集群中其他的机器上。参见一下例子中用户闭包中引用的 initialWeights 会被自动发送到集群其他机器上。</p>
<pre>
lines &lt;- textFile(sc, &quot;hdfs://data.txt&quot;)
   initialWeights &lt;- runif(n=D, min = -1, max = 1)
   createMatrix &lt;- function(line) {
     as.numeric(unlist(strsplit(line, &quot; &quot;))) %*% t(initialWeights)
   }
   # initialWeights is automatically serialized
   matrixRDD &lt;- lapply(lines, createMatrix)
</pre>
<p>用户还可以很容易的在已经安装了R开发包的集群上使用SparkR。includePackage 命令用于指示在每个集群上执行操作前读取开发包。以下是个例子：</p>
<pre>
generateSparse &lt;- function(x) {
    # Use sparseMatrix function from the Matrix package
    sparseMatrix(i=c(1, 2, 3), j=c(1, 2, 3), x=c(1, 2, 3))
  }
  includePackage(sc, Matrix)
  sparseMat &lt;- lapplyPartition(rdd, generateSparse)
</pre>
<p>针对SparkR发布的消息，大数据创业公司DataBricks的创始人之一<a href="http://weibo.com/hashjoin">@hashjoin</a>（辛湜）在微博上评论到：</p>
<blockquote> 
 <p>R是数据分析最常用的工具之一，但是R能处理的数据不能大于一台机器的内存。过去有一些R和Hadoop结合的尝试一般都性能低下，用户体验差。今天AMPLab发布了R的Spark前端，利用R进行大数据交互分析，也可以在节点上利用R的数据分析库，是大数据的一个新利器。</p> 
</blockquote>
<p><a href="http://weibo.com/n/vinW">@vinW</a>：</p>
<blockquote> 
 <p>我一直就说R matlab 和Spark其实是一路的，内存流派的。Spark这个分布式的高端搞法必将重振内存计算这个领域。</p> 
</blockquote>
<p><a href="http://weibo.com/sunbjt">@刘思喆</a>：</p>
<blockquote> 
 <p>重磅消息，比预想的要早很多。</p> 
</blockquote>
<hr />
<p>感谢<a href="http://www.infoq.com/cn/author/辛湜">辛湜</a>对本文的审校。</p>
<p>给InfoQ中文站投稿或者参与内容翻译工作，请邮件至<a href="mailto:editors@cn.infoq.com">editors@cn.infoq.com</a>。也欢迎大家通过新浪微博（<a href="http://www.weibo.com/infoqchina">@InfoQ</a>）或者腾讯微博（<a href="http://t.qq.com/infoqchina">@InfoQ</a>）关注我们，并与我们的编辑和其他读者朋友交流。</p><br><br><br><br><br><br></body></html>